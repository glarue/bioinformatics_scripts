#!/usr/bin/env python3

"""
usage: top_blast_hits.py [-h] [-n NUMBER_OF_HITS] [-e E_VALUE_CUTOFF] [-d]
                         [-s] [-m] [-r]
                         blast_file

Reports the top n BLAST hits for each query in a (tabular) blast output file

positional arguments:
  blast_file

optional arguments:
  -h, --help            show this help message and exit
  -n NUMBER_OF_HITS, --number_of_hits NUMBER_OF_HITS
                        number of hits to report for each unique query
                        (default: 1)
  -e E_VALUE_CUTOFF, --e_value_cutoff E_VALUE_CUTOFF
                        exclude hits with e-value greater than this value
                        (default: None)
  -d, --allow_duplicate_target_hits
                        allow multiple hits to the same subject to be included
                        (default: False)
  -s, --sort_by_name    sort output by name rather than bitscore (default:
                        False)
  -m, --memory_efficient
                        avoid reading entire dataset into memory at once, to
                        increase memory efficiency (default: False)
  -r, --redundant_ids   allow query and subject to share the same identifier
                        (default: False)

"""

# authorship information
__author__ = 'Graham E. Larue'
__maintainer__ = "Graham E. Larue"
__email__ = 'egrahamlarue@gmail.com'
__license__ = 'GPL'

import sys
import argparse
import time
from collections import defaultdict as dd
from biogl import get_runtime


parser = argparse.ArgumentParser(
    description="Reports the top n BLAST hits "
                "for each query in a (tabular) blast output file",
    formatter_class=argparse.ArgumentDefaultsHelpFormatter)
parser.add_argument("blast_file")
parser.add_argument(
    "-n", 
    "--number_of_hits",
    type=int,       
    help="number of hits to report for each unique query",                
    default=1)
parser.add_argument(
    "-e",
    "--e_value_cutoff",
    help="exclude hits with e-value greater than this value",
    type=float
)
parser.add_argument(
    "-d", 
    "--allow_duplicate_target_hits",
    action="store_true", 
    default=False,
    help="allow multiple hits to the same subject to be included")
parser.add_argument(
    "-s", 
    "--sort_by_name", 
    action="store_true", 
    default=False,
    help="sort output by name rather than bitscore")
parser.add_argument(
    "-m", 
    "--memory_efficient", 
    action="store_true", 
    default=False,                   
    help="avoid reading entire dataset into memory at once, "
         "to increase memory efficiency")
parser.add_argument(
    '-r',
    '--redundant_ids', 
    action='store_true', 
    default=False,
    help='allow query and subject to share the same identifier')

if len(sys.argv) == 1:
    parser.print_help()
    sys.exit(0)

args = parser.parse_args()

started = time.time()

# Figure out what arguments we're working with
BLASTFILE = args.blast_file
N = args.number_of_hits
EVALUE = args.e_value_cutoff
DUPES = args.allow_duplicate_target_hits
NAME_SORT = args.sort_by_name
MEM_REDUCE = args.memory_efficient
REDUNDANT_IDS = args.redundant_ids

# Dictionary to store hits for each query
hitdict = dd(list)
total_hits = 0

# Do the data analysis at once or trimming as we go
with open(BLASTFILE) as blast:
    for hit in blast:
        try:
            bits = hit.strip().split('\t')
            query = bits[0]
            subject = bits[1]
            e_val = float(bits[-2])
            if query == subject and REDUNDANT_IDS is False:
                continue
            if EVALUE and e_val > EVALUE:
                continue
            bitscore = float(bits[-1])
            # Attach the bitscore and subject to allow for sorting at the end
            index_tuple = (hit.strip(), bitscore, subject)
            hitdict[query].append(index_tuple)
            if MEM_REDUCE:  # ~50% slower, ~200x less memory usage
                hitdict[query] = sorted(hitdict[query], key=lambda x: x[1], reverse=True)[:N]
            total_hits += 1
        except:  # weird line formatting
            continue

# The {file} argument directs output to standard error rather than
# standard out, to maintain clean redirection of the filtered query
# output to a file
print("[#] Indexed {} BLAST hits".format(total_hits), file=sys.stderr)

processed = 0

for query, hits in sorted(hitdict.items()):
    # Higher bitscores are better
    sorted_hits = sorted(hits, key=lambda x: x[1], reverse=True)
    filtered_hits = []
    if not DUPES:  # filter to unique subject hits only
        seen_subjects = set()
        for h in sorted_hits:
            subject = h[-1]
            if subject in seen_subjects:
                continue
            else:
                filtered_hits.append(h)
                seen_subjects.add(subject)
        final_hits = filtered_hits
    else:
        final_hits = sorted_hits
    if NAME_SORT:
        final_hits = sorted(final_hits[:N], key=lambda x: x[0])
    print("\n".join([x[0] for x in final_hits[:N]]))
    processed += len(final_hits[:N])

runtime = get_runtime(started)

print("[#] Processed {} hits in {}".format(processed, runtime), file=sys.stderr)
sys.exit(0)
