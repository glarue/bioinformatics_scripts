#!/usr/bin/env python3

"""
usage: randl [-h] [-s SEED] file n

Retrieves a random sample of lines from a file.

positional arguments:
  file                  input file. If FASTA, will retrieve random
                        header/sequence pairs.
  n                     size of sample to retrieve.

optional arguments:
  -h, --help            show this help message and exit
  -s SEED, --seed SEED  seed value for the pseudo-random algorithm

"""

# authorship information
__author__ = 'Graham E. Larue'
__maintainer__ = "Graham E. Larue"
__email__ = 'egrahamlarue@gmail.com'
__license__ = 'GPL'

import sys
import argparse
import random
import mmap
from biogl import fasta_parse
from collections import deque

#TODO update with reservoir sampling function

def check_fasta(f):
    """
    Checks for hallmark features of a FASTA file and returns a boolean.
    
    """
    with open(f) as infile:
        for line in infile:
            if line.startswith("#"):
                continue
            elif line.startswith(">"):
                return True
            else:
                return False

    return False


# this version is slightly faster (memory-mapped file object optimized
# for line reading)
def count_lines(filename):
    fa = check_fasta(filename)
    with open(filename) as f:
        buf = mmap.mmap(f.fileno(), 0, prot=mmap.PROT_READ)
        line_count = 0
        while True:
            line = buf.readline().decode()
            if not line:
                break
            if fa:
                if line.startswith('>'):
                    line_count += 1
            else:
                line_count += 1
    return line_count


def line_iterator(f):
    """
    Yield lines of a file, and if FASTA yields newline-joined
    header/sequence pairs
    
    """
    # Check if file is FASTA to determine correct parsing behavior
    is_fa = check_fasta(f)
    if is_fa:
        for h, s in fasta_parse(f, trim_header=False, separator='\n'):
            yield ">{}\n{}".format(h, s)
    else:
        with open(f) as infile:
            for l in infile:
                yield l.strip()


parser = argparse.ArgumentParser(description=(
    "Retrieves a random sample of lines from a file."))
parser.add_argument(
    'input_file',
    metavar='file',
    help='input file. If FASTA, will retrieve random header/sequence pairs.')
parser.add_argument(
    'sample_size',
    metavar='n',
    type=int,
    help='size of sample to retrieve.')
parser.add_argument(
    '-s',
    '--seed',
    help='seed value for the pseudo-random algorithm',
    type=int)

args = parser.parse_args()

INFILE = args.input_file
SAMPLE_N = args.sample_size
SEED = args.seed

# reproducible selection process
if SEED:
    random.seed(SEED)

# Get a count of all the lines (or header) in the file
TOTAL_LINES = count_lines(INFILE)

# deque object allows fast trimming of list-like data
RDM_SET = deque(sorted(random.sample(range(TOTAL_LINES), SAMPLE_N)))

# Iterate over lines or header/sequence pairs and print those in the random
# sample set
record_count = 0
for line in line_iterator(INFILE):
    try:
        if record_count == RDM_SET[0]:
            RDM_SET.popleft()
            print(line)
        record_count += 1
    except IndexError:
        sys.exit(0)
