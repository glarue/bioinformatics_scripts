#!/usr/bin/env python3

"""
usage: fasterq_dump [-h] [-f FILE] [-k] [-t] [-w] [-m] [-u {all,curl,wget,prefetch}] [accessions [accessions ...]]

A program to run fastq-dump sequentially on a list of accession numbers. Will automatically detect if reads are single- or paired-end and will
run fastq-dump accordingly, adding proper ID suffixes as needed. Accession numbers may be provided directly, or in a file using the -f option.
If provided directly, accessions may be comma or space separated, or hyphen-separated to specify a range, e.g. SRR123455, SRR123456, SRR123457
or SRR123455-SRR123457. Any other args will be passed to fastq-dump.

positional arguments:
  accessions            Space, comma or hyphen (range) separated list of SRA accession numbers (e.g. SRR123456 SRR123457 or SRR123456-SRR123460)

optional arguments:
  -h, --help            show this help message and exit
  -f FILE, --file FILE  File with SRA accession numbers on separate lines
  -k, --keep_sra_files  Keep SRA files after dumping to FASTQ format
  -t, --trinity_compatible_ids
                        rename read IDs in paired-end data to ensure downstream compatibility with Trinity
  -w, --overwrite       overwrite any matching local SRA files
  -m, --manual          do not auto-detect read type (manual entry of e.g. "--split-files" required)
  -u {all,curl,wget,prefetch}, --utilities {all,curl,wget,prefetch}
                        specify the utilities(s) to use to fetch the SRA file(s) (default: all)

"""

# authorship information
__author__ = 'Graham E. Larue'
__maintainer__ = "Graham E. Larue"
__email__ = 'egrahamlarue@gmail.com'
__license__ = 'GPL'

import sys
import os
import subprocess
import shlex
import time
import argparse
from collections import namedtuple
from functools import partial
from itertools import zip_longest
from biogl import get_runtime, recursive_items

# taken directly from https://docs.python.org/3/library/itertools.html#recipes
def grouper(iterable, n, fillvalue=None):
    "Collect data into fixed-length chunks or blocks"
    # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx"
    args = [iter(iterable)] * n
    return zip_longest(*args, fillvalue=fillvalue)


def fastq_parse(fastq):
    FqRec = namedtuple(
        "FqRec",
        [
            "id",
            "seq",
            "meta",
            "quality",
            "full_record",
            "cleaned"
        ]
    )
    for group in grouper(fastq, 4):  # blocks of 4 lines
        if None in group:
            continue
        # assign fastq lines to a namedtuple output
        record_block = [g.strip() for g in group]
        full_record = "\n".join(record_block)
        fq_id, fq_seq, fq_meta, fq_quality = record_block
        fq_id = fq_id.split()[0]
        fq_meta = fq_meta[0]
        cleaned = "\n".join([fq_id, fq_seq, fq_meta, fq_quality])
        record_info = FqRec(fq_id, fq_seq, fq_meta, fq_quality, full_record, cleaned)

        yield record_info


def paired_check(acc):
    """
    Runs fastq-dump on the first 2 reads of an accession number
    <acc> to determine whether the data is single- or paired-end.

    Returns "paired", "single" or None.

    """
    test_dump = "fastq-dump {} -X 6 --split-files -I --stdout".format(acc)
    test_args = shlex.split(test_dump)
    # stderr of subprocess sent to /dev/null to silence fastq-dump progress output
    test_process = subprocess.run(
        test_args, 
        stdout=subprocess.PIPE,
        stderr=subprocess.DEVNULL, 
        universal_newlines=True,
        check=True
    )
    suffixes = set()
    for rec in fastq_parse(test_process.stdout.strip().split('\n')):
        # it's safe to just take the last character because of the -I flag
        # in the fastq-dump call
        suffixes.add(rec.id[-1])
    if len(suffixes) == 2:
        read_type = "paired"
    elif len(suffixes) == 1:
        read_type = "single"
    else:
        print(
            '[!] Read type ambiguous (read suffixes: {})'.format(suffixes), 
            file=sys.stderr)
        read_type = None

    return read_type


# def fetch_sra(acc, overwrite=False):
#     """
#     Grabs an SRA file from NCBI.

#     """
#     sra_filename = '{}.sra'.format(acc)

#     # if local file already exists, use it instead
#     if os.path.isfile(sra_filename) and overwrite is False:
#         print(
#             '[#] Using existing SRA file: {}'.format(sra_filename),
#             file=sys.stderr
#         )
#         return sra_filename

#     alpha = acc[:3]
#     first_six = acc[:6]

#     # build file path to SRA data
#     base_path = 'ftp://ftp-trace.ncbi.nlm.nih.gov'

#     # pattern of path:
#     #  /sra/sra-instant/reads/ByRun/sra/{SRR|ERR|DRR}/
#     # <first 6 characters of accession>/<accession>/<accession>.sra
#     path_bits = [alpha, first_six, acc, sra_filename]
#     relative_path = '/'.join(path_bits)
#     sra_path = '/sra/sra-instant/reads/ByRun/sra/{}'.format(relative_path)
#     full_path = base_path + sra_path

#     # old address style first
#     ret_val = subprocess.run(['wget', full_path, '-O', sra_filename]).returncode
#     if ret_val != 0:
#         print(
#             '[!] Could not find SRA file at {}'
#             '\nTrying alternative'.format(full_path)
#         )
#         full_path = 'https://sra-download.ncbi.nlm.nih.gov/sos/sra-pub-run-1/{}/{}.1'.format(acc, acc)
#         ret_val = subprocess.run(['wget', '--user-agent="Mozilla"', full_path, '-O', sra_filename]).returncode

#     return sra_filename

def build_sra_path(acc):
    alpha = acc[:3]
    first_six = acc[:6]
    sra_filename = '{}.sra'.format(acc)
    # build file path to SRA data
    base_path = 'ftp://ftp-trace.ncbi.nlm.nih.gov'

    # pattern of path:
    #  /sra/sra-instant/reads/ByRun/sra/{SRR|ERR|DRR}/
    # <first 6 characters of accession>/<accession>/<accession>.sra
    path_bits = [alpha, first_six, acc, sra_filename]
    relative_path = '/'.join(path_bits)
    sra_path = '/sra/sra-instant/reads/ByRun/sra/{}'.format(relative_path)
    full_path = base_path + sra_path

    return full_path


def local_sra_check(acc):
    sra_filename = '{}.sra'.format(acc)
    if os.path.isfile(sra_filename) and os.path.getsize(sra_filename) > 0:
        return sra_filename
    else:
        return False

#TODO propagate quiet arg from argparse to this function call
def fetch_prefetch(acc, quiet=True):
    fn = '{}.sra'.format(acc)
    cwd = os.getcwd()
    max_size_kb = '80000000'  # 80 GB
    try: 
        result = subprocess.run(
            [
                'prefetch', 
                acc, 
                '-O', 
                cwd, 
                '-o', 
                fn, 
                '-p', 
                '--max-size', 
                max_size_kb
            ],
            stdout=subprocess.PIPE
        )
        ret_code = result.returncode
        if not quiet:
            print(result.stdout, file=sys.stderr)
    except:
        ret_code = 42
    if ret_code != 0:
        print(
            '[!] Downloading {} via prefetch failed'.format(acc), 
            file=sys.stderr
        )
        return None
    else:
        return fn


def fetch_direct(acc, protocols=['wget', 'curl']):
    fn = '{}.sra'.format(acc)
    total_retries = 2
    sra_path = None
    srapath_retry = 1
    while srapath_retry <= total_retries and sra_path is None:
        try:
            sra_path = subprocess.run(
                ['srapath', acc], 
                check=True, 
                stdout=subprocess.PIPE, 
                universal_newlines=True
            ).stdout.strip()
        except: # utility not installed or srapath error
            print(
                '[!] Failed to resolve URL via srapath ({}/{})'
                .format(srapath_retry, total_retries), file=sys.stderr
            )
            srapath_retry += 1
            time.sleep(5)
            continue
    if sra_path is None:
        print(
            '[!] Unable to source srapath; using old-style URL construction',
            file=sys.stderr
        )
        sra_path = build_sra_path(acc)
    print('[#] SRA URL: {}'.format(sra_path), file=sys.stderr)
    downloaders = {
        'curl': ['-f', '-L', '--output', fn, sra_path],
        'wget': ['-O', fn, sra_path]
    }
    ret_val = None
    for p in protocols:
        d_args = downloaders[p]
        d_cmds = [p] + d_args
        retry_n = 1
        while retry_n <= total_retries and ret_val is None:
            print(
                '[#] Trying direct download ({}/{}): {}'.format(
                    retry_n, total_retries, ' '.join(d_cmds)), file=sys.stderr)
            ret_code = subprocess.run(d_cmds).returncode
            if ret_code != 0:
                print('[!] Download command failed', file=sys.stderr)
                retry_n += 1
                ret_val = None
            else:
                return fn        
                # ret_val = fn
                # break

    return ret_val


def fetch_sra(acc, utilities, overwrite=False):
    """
    Grabs an SRA file from NCBI.

    """
    # if local file already exists, use it instead
    local_filename = local_sra_check(acc)
    if local_filename and overwrite is False:
        print(
            '[#] Using existing SRA file: {}'.format(local_filename),
            file=sys.stderr
        )
        return local_filename

    # different fetch methods in order of increasing desperation
    if utilities in ('wget', 'curl'):
        fetch_funcs = [partial(fetch_direct, protocols=[utilities])]
    elif utilities == 'prefetch':
        fetch_funcs = [fetch_prefetch]
    elif utilities == 'all':
        fetch_funcs = [fetch_prefetch, fetch_direct]
    else:
        return None
    sra_filename = None
    for f in fetch_funcs:
        sra_filename = f(acc)
        if sra_filename is not None:
            break

    return sra_filename


def acc_list_from_file(acc_file):
    accs = []
    with open(acc_file) as f:
        for l in f:
            accs.append(l.strip())
    return accs


def format_range(range_string):
    begin, end = range_string.split('-')
    prefix = begin[:3]
    suffix = begin[3:]
    num_length = len(suffix)
    # leading zeroes are removed in the map call below, so calculate
    # how many there might be to add them in later
    # leading_zero_n = len(suffix) - len(suffix.lstrip('0'))
    # leading_zero_string = '0' * leading_zero_n
    start, stop = list(map(int, [e[3:] for e in [begin, end]]))
    numeric_range = list(range(start, stop+1))
    zero_strings = ['0' * (num_length - len(str(n))) for n in numeric_range]
    formatted_range = [
        prefix + zeroes + str(r)
        for zeroes, r in zip(zero_strings, numeric_range)
    ]

    return formatted_range


def clean_args(arguments):
    stage_1 = []
    for arg in arguments:
        new_arg = arg.replace(',', ' ')
        cleaned = new_arg.split()
        stage_1 += cleaned
    final_args = []
    for c in stage_1:
        if '-' not in c:
            final_args.append(c)
            continue
        acc_range = format_range(c)
        final_args += acc_range

    return final_args


def fastq_exists(acc, paired=False):
    if paired:
        fns = ['{}_1.fastq'.format(acc), '{}_2.fastq'.format(acc)]
    else:
        fns = ['{}.fastq'.format(acc)]
    existing_files = recursive_items(pattern='{}.*fastq.*'.format(acc))
    files_already_present = True
    for f in fns:
        if not any(f in e for e in existing_files):
            files_already_present = False
            break
    
    return files_already_present

#TODO: remove previous log; add timestamp; add success/failure method(s)
def write_log(logfn, acc, success=True):
    status = 'success'
    if success is not True:
        status = 'fail'
    outbits = [acc, status]
    with open(logfn, 'a') as log:
        log.write('\t'.join(outbits) + '\n')
    
    return

parser = argparse.ArgumentParser(
    description='A program to run fastq-dump sequentially on a list of '
    'accession numbers. Will automatically detect if reads are single- or '
    'paired-end and will run fastq-dump accordingly, adding proper ID '
    'suffixes as needed. Accession numbers may be provided directly, or '
    'in a file using the -f option. If provided directly, accessions may '
    'be comma or space separated, or hyphen-separated to specify a range, '
    'e.g. SRR123455, SRR123456, SRR123457 or SRR123455-SRR123457. Any other '
    'args will be passed to fastq-dump.'
)
parser.add_argument(
    'accessions',
    nargs='*',
    help=(
        'Space, comma or hyphen (range) separated list of SRA '
        'accession numbers (e.g. SRR123456 SRR123457 or SRR123456-SRR123460)')
)
parser.add_argument(
    '-f',
    '--file',
    help='File with SRA accession numbers on separate lines'
)
parser.add_argument(
    '-k',
    '--keep_sra_files',
    help='Keep SRA files after dumping to FASTQ format',
    action='store_true'
)
parser.add_argument(
    '-t',
    '--trinity_compatible_ids',
    help=(
        'rename read IDs in paired-end data to ensure '
        'downstream compatibility with Trinity'),
    action='store_true'
)
parser.add_argument(
    '-w',
    '--overwrite',
    help=(
        'overwrite any matching local SRA/FASTQ files'),
    action='store_true'
)
parser.add_argument(
    '-m',
    '--manual',
    action='store_true',
    help=(
        'do not auto-detect read type '
        '(manual entry of e.g. "--split-files" required)'
    )
)
parser.add_argument(
    '-u',
    '--utilities',
    choices=('all', 'curl', 'wget', 'prefetch'),
    help=(
        'specify the utilities(s) to use to fetch the SRA file(s) '
        '(default: all)'),
    default='all'
)
parser.add_argument(
    '--log',
    help=('create a log file with the success/failure status for each acc'),
    action='store_true'
)

# small test SRA accs: SRR6853039 (single), SRR7658733 (paired)

if len(sys.argv) == 1:
    sys.exit(parser.print_help())

args, extra_args = parser.parse_known_args()

if args.file:
    accs = acc_list_from_file(args.file)
else:
    accs = clean_args(args.accessions)

if len(accs) > 25:
    choice = input(
        'Are you sure you want to run this on {} files? (y/n): '
        .format(len(accs)))
    if choice.lower() != 'y':
        sys.exit('Aborting run.')

# rename ids using fastq-dump's built-in if desired
shared_args = []
paired_args = []

if args.trinity_compatible_ids:
    id_arg = ' --defline-seq \'@$ac.$si:$sn[_$rn]/$ri\''
    shared_args.append(id_arg)

if not args.manual:
    paired_args.append('--split-files')

cmds = {
    'paired': 'fastq-dump {} '.format(' '.join(shared_args + paired_args)),
    'single': 'fastq-dump {} '.format(' '.join(shared_args))
}

sra_files = []

extra_arg_string = ' '.join(extra_args)

start_time = time.time()

log_name = 'fasterq_dump.log'

for acc in accs:
    acc_success = False
    if '-X' not in extra_args:
        acc_filename = fetch_sra(acc, args.utilities, args.overwrite)
        if acc_filename is None:
            print(
                '[!] Could not fetch SRA file ({}); skipping.'.format(acc), 
                file=sys.stderr
            )
        else:
            acc_success = True
            sra_files.append(acc_filename)
        if args.log:
            write_log(log_name, acc, success=acc_success)
    else:
        # we don't want to pre-fetch SRA since we're
        # only getting a subset of the reads
        acc_filename = acc
    if acc_filename is None:
        continue
    read_type = paired_check(acc_filename)
    if read_type is not None:
        print(
            '[#] Detected read type for {}: {}'.format(acc, read_type),
            file=sys.stderr
        )
    else:
        read_type = 'single'
    if read_type == 'paired':
        paired_flag = True
    else:
        paired_flag = False
    fq_present = fastq_exists(acc, paired=paired_flag)
    if fq_present and not args.overwrite:
        print(
            '[!] Skipping fastq-dump on {} because existing FASTQ files found'
            .format(acc), file=sys.stderr
        )
    else:
        cmd = cmds[read_type] + acc_filename + ' ' + extra_arg_string
        dump_args = shlex.split(cmd)
        print('[#] Running command \'{}\''.format(cmd), file=sys.stderr)
        subprocess.run(dump_args)
        # allow time for fastq-dump to print to stdout
        time.sleep(2)
    if not args.keep_sra_files:
        if os.path.isfile(acc_filename):
            os.remove(acc_filename)

runtime = get_runtime(start_time)

print(
    '[#] All commands finished in {}. Exiting now.'.format(runtime), 
    file=sys.stderr
)

sys.exit(0)
